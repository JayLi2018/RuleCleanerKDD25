{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b355df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(\"../../wrench/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99217ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/chenjieli/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chenjieli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rulecleaner_src.lfs_tree import keyword_labelling_func_builder\n",
    "from rulecleaner_src.TreeRules import SPAM, HAM, ABSTAIN, PredicateNode\n",
    "from rulecleaner_src.LFRepair import populate_violations, fix_rules_with_solver_input\n",
    "from rulecleaner_src.utils import run_label_model_with_funcs, select_user_input, clean_text\n",
    "\n",
    "\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from snorkel.labeling import (\n",
    "\tLabelingFunction, \n",
    "\tlabeling_function, \n",
    "\tPandasLFApplier, \n",
    "\tLFAnalysis,\n",
    "\tfilter_unlabeled_dataframe\n",
    "\t)\n",
    "from snorkel.labeling.model import MajorityLabelVoter, LabelModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import matplotlib.patches as mpatches\n",
    "import pulp\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "from IPython.display import Image, display \n",
    "import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7776d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulecleaner_src.example_tree_rules import (\n",
    "gen_amazon_funcs,\n",
    "gen_professor_teacher_funcs,\n",
    "gen_painter_architecht_funcs,\n",
    "gen_imdb_funcs,\n",
    "gen_pj_funcs,\n",
    "gen_pp_funcs,\n",
    "gen_yelp_funcs,\n",
    "gen_plots_funcs,\n",
    "gen_fakenews_funcs,\n",
    "gen_dbpedia_funcs,\n",
    "gen_agnews_funcs,\n",
    "gen_tweets_funcs,\n",
    "gen_spam_funcs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f55038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"plots\": gen_plots_funcs,\n",
    "    \"amazon\": gen_amazon_funcs,\n",
    "    \"dbpedia\": gen_dbpedia_funcs,\n",
    "    \"agnews\": gen_agnews_funcs,\n",
    "    \"physician_professor\": gen_pp_funcs,\n",
    "    \"imdb\": gen_imdb_funcs,\n",
    "    \"fakenews\": gen_fakenews_funcs,\n",
    "    \"yelp\": gen_yelp_funcs,\n",
    "    \"photographer_journalist\": gen_pj_funcs,\n",
    "    \"professor_teacher\": gen_professor_teacher_funcs,\n",
    "    \"painter_architect\": gen_painter_architecht_funcs,\n",
    "    \"tweets\": gen_tweets_funcs,\n",
    "    \"spam\": gen_spam_funcs,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3165576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulecleaner_src.main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0bee147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_input_sizes = [40]\n",
    "# random_states = [1,2,3,4,5,6,7,8, 9, 10]\n",
    "random_states = [1]\n",
    "lf_acc_threshs = [0.7]\n",
    "instance_acc_threshs = [0.8]\n",
    "non_abstain_threshs = [0.8]\n",
    "datasets = list(dataset_dict)\n",
    "func_dictionary = [dataset_dict]\n",
    "instance_acc_on_valids=[False]\n",
    "use_non_abstains=[False]\n",
    "# model_types=['dawidskene','flyingsquid']\n",
    "# model_types = ['majority', 'weighted_majority', ]\n",
    "model_types = ['fable', ]\n",
    "pfile_name_prefix = ['additional_other_label_models_april15/']\n",
    "num_class=[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "393647cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = list(itertools.product(\n",
    "    user_input_sizes,\n",
    "    lf_acc_threshs,\n",
    "    instance_acc_threshs,\n",
    "    non_abstain_threshs,\n",
    "    datasets,\n",
    "    random_states,\n",
    "    func_dictionary,\n",
    "    instance_acc_on_valids,\n",
    "    use_non_abstains,\n",
    "    pfile_name_prefix,\n",
    "    ['witan'],\n",
    "    num_class,\n",
    "    model_types\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f25219-3d4a-42e2-af10-db43a5172bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'plots',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'amazon',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'dbpedia',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'agnews',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'physician_professor',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'imdb',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'fakenews',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'yelp',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'photographer_journalist',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'professor_teacher',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'painter_architect',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'tweets',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable'),\n",
       " (40,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  'spam',\n",
       "  1,\n",
       "  {'plots': <function rulecleaner_src.example_tree_rules.gen_plots_funcs()>,\n",
       "   'amazon': <function rulecleaner_src.example_tree_rules.gen_amazon_funcs()>,\n",
       "   'dbpedia': <function rulecleaner_src.example_tree_rules.gen_dbpedia_funcs()>,\n",
       "   'agnews': <function rulecleaner_src.example_tree_rules.gen_agnews_funcs()>,\n",
       "   'physician_professor': <function rulecleaner_src.example_tree_rules.gen_pp_funcs()>,\n",
       "   'imdb': <function rulecleaner_src.example_tree_rules.gen_imdb_funcs()>,\n",
       "   'fakenews': <function rulecleaner_src.example_tree_rules.gen_fakenews_funcs()>,\n",
       "   'yelp': <function rulecleaner_src.example_tree_rules.gen_yelp_funcs()>,\n",
       "   'photographer_journalist': <function rulecleaner_src.example_tree_rules.gen_pj_funcs()>,\n",
       "   'professor_teacher': <function rulecleaner_src.example_tree_rules.gen_professor_teacher_funcs()>,\n",
       "   'painter_architect': <function rulecleaner_src.example_tree_rules.gen_painter_architecht_funcs()>,\n",
       "   'tweets': <function rulecleaner_src.example_tree_rules.gen_tweets_funcs()>,\n",
       "   'spam': <function rulecleaner_src.example_tree_rules.gen_spam_funcs()>},\n",
       "  False,\n",
       "  False,\n",
       "  'additional_other_label_models_april15/',\n",
       "  'witan',\n",
       "  2,\n",
       "  'fable')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55a5fe6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_input_size = 40\n",
      "lf_acc_thresh = 0.7\n",
      "instance_acc_thresh = 0.8\n",
      "min_non_abstain_thresh = 0.8\n",
      "dataset_name = plots\n",
      "random_state = 1\n",
      "funcs_dictionary = {'plots': <function gen_plots_funcs at 0x3335f4c10>, 'amazon': <function gen_amazon_funcs at 0x3335f4820>, 'dbpedia': <function gen_dbpedia_funcs at 0x3335f4d30>, 'agnews': <function gen_agnews_funcs at 0x3335f4dc0>, 'physician_professor': <function gen_pp_funcs at 0x3335f4af0>, 'imdb': <function gen_imdb_funcs at 0x3335f49d0>, 'fakenews': <function gen_fakenews_funcs at 0x3335f4ca0>, 'yelp': <function gen_yelp_funcs at 0x3335f4b80>, 'photographer_journalist': <function gen_pj_funcs at 0x3335f4a60>, 'professor_teacher': <function gen_professor_teacher_funcs at 0x3335f48b0>, 'painter_architect': <function gen_painter_architecht_funcs at 0x3335f4940>, 'tweets': <function gen_tweets_funcs at 0x3335f4e50>, 'spam': <function gen_spam_funcs at 0x3335f4ee0>}\n",
      "instance_acc_on_valid = False\n",
      "use_non_abstain = False\n",
      "pickle_result_file_name_prefix = additional_other_label_models_april15/\n",
      "lf_source = witan\n",
      "num_possible_labels = 2\n",
      "model_type = fable\n",
      "func names:\n",
      "\n",
      "rid:0PredicateNode(id=1, pred=keyword_predicate-word-(world,fight,war,agent))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=0)*************************\n",
      "rid:1PredicateNode(id=1, pred=keyword_predicate-word-(woman))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:2PredicateNode(id=1, pred=keyword_predicate-word-(marriage,student,mysterious))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:3PredicateNode(id=1, pred=keyword_predicate-word-(fails))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:4PredicateNode(id=1, pred=keyword_predicate-word-(couple,life,family,daughter,ex,town,friend,years,way,guy))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:5PredicateNode(id=1, pred=keyword_predicate-word-(relationship,york))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:6PredicateNode(id=1, pred=keyword_predicate-word-(story))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:7PredicateNode(id=1, pred=keyword_predicate-word-(takes))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:8PredicateNode(id=1, pred=keyword_predicate-word-(girl))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)*************************\n",
      "rid:9PredicateNode(id=1, pred=keyword_predicate-word-(friends))\n",
      "    LabelNode(id=2, label=-1)\n",
      "    LabelNode(id=3, label=1)\n",
      "initial_vectors: (1937, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenjieli/Desktop/RuleCleaner/rulecleaner_src/../rulecleaner_src/utils.py:83: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sentences_df = pd.read_sql(f'SELECT * FROM {dataset_name}', conn)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'kernel_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ip \u001b[38;5;129;01min\u001b[39;00m input_params:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mip\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/RuleCleaner/rulecleaner_src/../rulecleaner_src/main.py:89\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(user_input_size, lf_acc_thresh, instance_acc_thresh, min_non_abstain_thresh, dataset_name, random_state, funcs_dictionary, instance_acc_on_valid, use_non_abstain, pickle_result_file_name_prefix, lf_source, num_possible_labels, model_type)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*************************\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m funcs]))\n\u001b[1;32m     88\u001b[0m first_snorkel_run_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 89\u001b[0m df_sentences_filtered, correct_preds_by_snorkel, wrong_preds_by_snorkel, filtered_vectors, correct_predictions, incorrect_predictions, global_accuracy, global_accuracy_on_valid \u001b[38;5;241m=\u001b[39m\u001b[43mrun_label_model_with_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                                                                                                                                                                                                             \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                                                                                                                                                                                                             \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                                                                                                                                                                                                             \u001b[49m\u001b[43mcardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_possible_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                                                                                                                                                                                                             \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m first_snorkel_run_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     95\u001b[0m first_snorkel_run_time \u001b[38;5;241m=\u001b[39m first_snorkel_run_end \u001b[38;5;241m-\u001b[39m first_snorkel_run_start\n",
      "File \u001b[0;32m~/Desktop/RuleCleaner/rulecleaner_src/../rulecleaner_src/utils.py:146\u001b[0m, in \u001b[0;36mrun_label_model_with_funcs\u001b[0;34m(dataset_name, funcs, conn, cardinality, model_type)\u001b[0m\n\u001b[1;32m    144\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(probs_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mFable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(initial_vectors, n_class\u001b[38;5;241m=\u001b[39mcardinality)\n\u001b[1;32m    148\u001b[0m     probs_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(initial_vectors)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'kernel_function'"
     ]
    }
   ],
   "source": [
    "for ip in input_params:\n",
    "    main(*ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af118f78-97f3-4a15-af92-f739257fc4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
