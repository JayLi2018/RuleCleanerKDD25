{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c954d52f-b89e-4621-965d-9aaf6189e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016930a0-10b9-4244-8df0-6eeb62edc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_datasets = [\n",
    "    'tweets',\n",
    "    'spam',\n",
    "    'plots',\n",
    "    'amazon',\n",
    "    'agnews',\n",
    "    'physician_professor',\n",
    "    'imdb',\n",
    "    'fakenews',\n",
    "    'yelp',\n",
    "    'professor_teacher',\n",
    "    'painter_architect',\n",
    "\n",
    "]\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"label\",\n",
    "    user=\"postgres\",\n",
    ")\n",
    "\n",
    "mapping_dicts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167417fa-ba1d-4c1e-9bfe-c381ae2b84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets\n",
      "   count  class     label\n",
      "0   2363      0  positive\n",
      "1   9178      1  negative\n",
      "\n",
      "\n",
      "spam\n",
      "   count  class label\n",
      "0    747      1  spam\n",
      "1   4825      0   ham\n",
      "\n",
      "\n",
      "plots\n",
      "   count  class    label\n",
      "0    915      0   action\n",
      "1   1030      1  romance\n",
      "\n",
      "\n",
      "amazon\n",
      "    count  class     label\n",
      "0   99936      0  positive\n",
      "1  100064      1  negative\n",
      "\n",
      "\n",
      "agnews\n",
      "   count  class       label\n",
      "0  30000      0  Technology\n",
      "1  30000      1    Business\n",
      "\n",
      "\n",
      "physician_professor\n",
      "   count  class      label\n",
      "0  27238      1  physician\n",
      "1  27238      0  professor\n",
      "\n",
      "\n",
      "imdb\n",
      "   count  class     label\n",
      "0  25000      0  negative\n",
      "1  25000      1  positive\n",
      "\n",
      "\n",
      "fakenews\n",
      "   count  class label\n",
      "0  21417      0  true\n",
      "1  23481      1  fake\n",
      "\n",
      "\n",
      "yelp\n",
      "   count  class     label\n",
      "0  19000      0  negative\n",
      "1  19000      1  positive\n",
      "\n",
      "\n",
      "professor_teacher\n",
      "   count  class      label\n",
      "0  12294      1  professor\n",
      "1  12294      0    teacher\n",
      "\n",
      "\n",
      "painter_architect\n",
      "   count  class      label\n",
      "0   6118      0    painter\n",
      "1   6118      1  architect\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/1608051740.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n"
     ]
    }
   ],
   "source": [
    "for ud in used_datasets:\n",
    "    print(ud)\n",
    "    info_df = pd.read_sql(f'select count(*), class, label from {ud} group by class, label', conn)\n",
    "    print(info_df)\n",
    "    result = dict(zip(info_df['label'], info_df['class']))\n",
    "    mapping_dicts[ud]= result\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedaecdb-f63e-457d-8ec2-9c07ab0c4575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1c61e933744d4d8aff6eedcd8d8258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table tweets: 2\n",
      "Clustered DataFrame for tweets saved to clustered_tweets.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec135794e60436b8f25e31d4f19df9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table spam: 2\n",
      "Clustered DataFrame for spam saved to clustered_spam.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e271b7ea124b7da4c30c3a0b23fe20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table plots: 2\n",
      "Clustered DataFrame for plots saved to clustered_plots.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed655fc49c90425183b6af5b2a1cf17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table amazon: 5\n",
      "Clustered DataFrame for amazon saved to clustered_amazon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3131840f0744e5ae7ec7a80129c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table agnews: 2\n",
      "Clustered DataFrame for agnews saved to clustered_agnews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7314f0901c948d6898fb850a44be59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table physician_professor: 2\n",
      "Clustered DataFrame for physician_professor saved to clustered_physician_professor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816f834e96ef422c9d852c57e7e47a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table imdb: 2\n",
      "Clustered DataFrame for imdb saved to clustered_imdb.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bbd33b5ac7418b95d585d38d1ed5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table fakenews: 2\n",
      "Clustered DataFrame for fakenews saved to clustered_fakenews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0219ecf776424dc0a9a33bf0c529697f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table yelp: 2\n",
      "Clustered DataFrame for yelp saved to clustered_yelp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5378ec4b5024660b43f0efc3d9b5383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table professor_teacher: 2\n",
      "Clustered DataFrame for professor_teacher saved to clustered_professor_teacher.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/1_4_3jg90p50ft92b5k6mgv00000gn/T/ipykernel_8967/2515698421.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d90f3a111745b3bafa2c8c6694a392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for table painter_architect: 2\n",
      "Clustered DataFrame for painter_architect saved to clustered_painter_architect.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "for k, v in mapping_dicts.items():\n",
    "    query = f\"SELECT * FROM {k}\"  # Make sure `k` is sanitized to prevent SQL injection\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    embeddings = model.encode(df['content'].tolist(), show_progress_bar=True)\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    k_values = range(2, 10)  # Test clusters from 2 to 10\n",
    "    \n",
    "    for num_clusters in k_values:\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        silhouette_scores.append(score)\n",
    "    \n",
    "    optimal_k = k_values[np.argmax(silhouette_scores)]\n",
    "    print(f\"Optimal number of clusters for table {k}: {optimal_k}\")\n",
    "    \n",
    "    # Step 3: Perform clustering with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    # Step 4: Save or process the updated DataFrame\n",
    "    output_file = f\"clustered_{k}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Clustered DataFrame for {k} saved to {output_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd5863-3448-4245-98fd-1f2e77d08b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
